---
title             : "Towards a \"Standard Model\" of Early Language Learning"
shorttitle        : "Standard Model of Language Learning"

author: 
  - name          : "George Kachergis"
    affiliation   : "1"
    corresponding : yes 
    address       : "450 Jane Stanford Way, Stanford, CA 94305"
    email         : "kachergis@stanford.edu"
  - name          : "Virginia A. Marchman"
    affiliation   : "1"
    corresponding : no 
    address       : "450 Jane Stanford Way, Stanford, CA 94305"
    email         : "marchman@stanford.edu"
  - name          : "Michael C. Frank"
    affiliation   : "1"
    corresponding : no 
    address       : "450 Jane Stanford Way, Stanford, CA 94305"
    email         : "mcfrank@stanford.edu"

affiliation:
  - id            : "1"
    institution   : "Stanford University"

authornote: |
  Department of Psychology

abstract: |
  A "standard model" is a theoretical framework that synthesizes observables into a quantitative consensus. Have we made progress towards this kind of synthesis for children’s early language learning? A number of computational models of early vocabulary learning assume that individual words are learned through an accumulation of environmental input. This assumption is also implicit in empirical work that emphasizes links between home language input and learning outcomes. However, models have typically focused on average performance, while empirical work has focused on variability. To capture individual variability, we relate accumulator models to Item-Response Theory models from psychometrics. Unfortunately, this formal connection also makes it clear that the currently available datasets cannot allow us to fully test these models, illustrating a critical need for theory in shaping new data collection. We end by considering the how this framework could shed light on to the role of language processing in acquistion, the connections of word learning to language learning more broadly, and the sources of variation in early language outcomes.
  
keywords          : "early language learning; language acquisition; vocabulary development"  
wordcount         : "3133"

bibliography      : ["references.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

Early language learning is a key challenge for cognitive science: how do we go from speechless, wordless infants to children who can use language expressively and creatively? 
The field of early language is often portrayed as mired in controversies, for example, around issues of innateness. 
We see a new synthesis emerging, however, based on new theoretical and empirical work on the growth of vocabulary. 
Our goal is to present this synthesis as the beginnings of a "standard model": a baseline theory that should be accepted widely in its outlines as a baseline summary[^1] of our beliefs and guide to future work, even if its assumptions still require rigorous evaluation.

[^1]: Note that "standard" here is not meant to imply that it is normative, but rather that the model is an accepted starting point for a description of early language learning.

In physics, the "standard model" is a widely-accepted theory from the 1970s that describes all known elementary particles along with three of the four known fundamental forces in the universe. 
Although it is known to be incomplete and even incorrect in places, physics’ Standard Model nonetheless explains a wide variety of empirical phenomena, allowing scientists and engineers to model physical interactions with great precision and accuracy and to design tests that inform theory revision. 
Psychology, in general, has been criticized for lacking such formal theories that inform and drive empirical research [@muthukrishna2019problem]. 
We feel this critique can be applied fairly to the field of language acquisition. 

Although a substantial literature uses computational models to simulate acquisition, these models (ours included) are often only loosely connected to the quantitative data gathered by working acquisition researchers. 
Yet despite this lack of formal connections, researchers studying early language learning often presuppose a common framework for early language learning (Figure 1). 
The core of this framework is that language input accumulates via repeated exposure, resulting in learning.
This framework underpins much of the broader policy discussion of individual variability in language learning and its links to environmental stimulation. 

This basic framework corresponds nicely with a class of computational models that has been explored in the word learning literature: accumulator models. 
Our aim is to make this connection explicit, using item-response theory (IRT) from psychometric testing as a framework for connecting empirical data and previous accumulator models. 
Sitting at a level of analysis between generic regressions and cognitive process models, data-analytic cognitive models of this type offer a way to implement our verbal theories and evaluate them quantitatively. 
Importantly, the goal is not to produce the "correct" model, but rather to explore the ways that model assumptions lead to predictions about specific patterns of data. 
In fact, the greatest value of such models is the ability to identify the areas of greatest mismatch between data and model, highlighting areas of the theory requiring further investigation [@tauber2016]. 


```{r, out.width="0.95\\linewidth", include=TRUE, fig.align="center", fig.cap=c("A schematic of the standard relationships between variables assumed in the literature on early language learning. It is generally assumed that child-directed speech (red) is more valuable than overheard speech (blue)."), echo=FALSE}
knitr::include_graphics("./figs/fig1_standard_model.pdf")
```


# Accumulator Models Are An Important Formalism For Describing Word Learning

We are interested in children’s vocabulary, which we define as the set of words they know.^[
What makes a word is its own separate and difficult question, especially as we look across languages. Are "dog" and "dogs" two separate words? 
If not, what about "mouse" and "mice"? These questions are relatively inconsequential in morphologically simple languages like English and Mandarin; yet they are quite a bit more difficult in morphologically more complex languages like Turkish or even agglutinating languages like Inuktitut. 
We sidestep this issue by noting that the Turkish or Inuktitut learner is accumulating *something* – whether or not we call it a word *per se*, our hypothesis is that this unit is being accumulated and that its accumulation will be subject to many of the same dynamics and information sources as words. 
For some initial data bearing out this supposition by comparing Turkish with other languages, see @braginsky2019.]
Driven by influential observations of the strong relationship between language input and children’s word learning [e.g., @huttenlocher1991early; @hart1995], computational modelers have created a range of hypotheses about how linguistic experiences drive learning. 
One class of models is *accumulator* models, which assume that linguistic experiences with words accumulate in separate registers (depicted as "buckets" in Figure 2), and that those registers exceeding a particular threshold are learned. 

Formalized theories of accumulative vocabulary growth have already contributed significantly to theoretical debate. 
For example, @mcmurray2007 elegantly demonstrated that children’s "vocabulary explosion" – an acceleration in vocabulary growth in the second year – can result from the steady accumulation of word tokens without changes in the environment or learning mechanism. 
Other work has examined similar models using more realistic distributions of words (i.e., Zipf-distributed), developmental change in learning mechanisms, and quantitative comparison to children’s aggregate vocabulary growth [@mayor2010; @hidaka2013; @mollica2017]. 
Although this work is exciting, these models have not yet made direct predictions about learning in individual children [@bergelson2020comprehension]. 

One difficulty in connecting such models to data is that the relevant variables are often measured in relative, rather than absolute, units. 
This practice is common. For example, measures of intelligence are given on a standardized scale defined by population variability. 
Yet in early language, we have access to absolute units of description, relatively unusually in a psychological domain. 
We can count how many words a child hears and express this as a rate [e.g., words per hour; @cristia2019], and we can similarly estimate how many words they know [e.g., by parents' reports of vocabulary size, @wordbankbook]. 
These absolute units give the potential for a model to make powerfully general quantitative predictions, which could be tested across different situations and populations [@dailey2021language]. 
As we describe below, however, few datasets have measurements of the relevant variables. 
This may be a case where theory outstrips data and further data collection efforts are necessary. 

```{r, out.width="0.7\\linewidth", include=TRUE, fig.align="center", fig.cap=c("An illustration of an accumulator model: each bucket represents the child’s knowledge about a particular word, and each token is a drop in the corresponding bucket. Some words are more difficult than others (i.e., have larger buckets). When a bucket is full, the corresponding word is considered to be learned. In theory, language input coming from child-directed speech (red) may count more than tokens in overheard speech (blue)."), echo=FALSE}
knitr::include_graphics("./figs/fig2_standard_model.pdf")
```

# Accumulator Models are Presupposed in the Empirical Literature

Since seminal work by @hart1995, the connection between children’s language input and the growth of vocabulary has been a topic of intense interest. 
Numerous studies have reported positive associations between these variables [e.g., @hoff2003specificity; @weisleder2013] - as predicted by accumulator models - though their magnitude varies across studies [@wang2020meta].
Such correlations are also partially moderated by other factors, including socioeconomic [@hoff2003specificity; @dailey2021language] and genetic [@hayiou2014language] variables.
Randomized interventions are the gold standard for measuring causal effects of parental language input on language learning, although such studies are costly and difficult to conduct. 
When such studies are conducted, they show modest but reliable effects [e.g., @suskind2016project], providing support for a causal connection between language input and outcomes. 
Critically, however, these studies only estimate the effect of the change in input on variation in outcome, hence, providing only a relative, rather than an absolute, estimate of how important input is to vocabulary learning.  

Reasoning from first principles, you cannot learn the word "table" if you do not hear it: input *must* predict learning. 
Yet correlational studies do not assess this relation fully, and instead assess whether *variation* in input relates to *variation* in learning. 
Thus, a second line of work that comes closer to assessing the importance of language input focuses, not on differences between children, but on differences between words. These studies use regression models to predict which *words* are easier or more difficult, averaging across children [e.g., @goodman2008does; @braginsky2019]. 
Such studies show a strong association between word frequency and the age at which children typically acquire particular words, especially for object labels. 
This general finding provides convergent support for accumulator models, absent the confound of differences between individuals. 

<!--
More broadly, this literature illustrates the value of a quantitative process model: under the standard model and its variants, we should be able to compute the expected relation between measures of input and vocabulary size. 
To the extent this model accounts for the data, it will support researchers’ current theory, but the model’s pattern of misfit to the data will likely be more informative, providing grist for the twin mills of theory development and empirical study.
-->

# Toward a "Standard" Accumulator Model

The core of the standard view of language learning is that it is a process of accumulation – individual experiences with words lead to their eventual acquisition. 
The more of these experiences a child receives, the faster their vocabulary grows. 
However, both children and words vary: children may learn faster or slower, and words can be more or less difficult to learn. 
Combining these ideas, the basic hypothesis is that a child’s vocabulary at a particular time should be predicted by their cumulative language exposure and learning rate, combined with the breadth and individual difficulties of the words to which have been exposed. 

The key contribution of such a baseline theory is that it establishes the link between the observable rates of words that children hear and their eventual knowledge of those words. 
For example, in principle, the model could establish how many occurrences of the word "dog" are needed by the average child in order to start understanding (or producing) "dog." 
Moreover, given a child’s vocabulary at a certain age, the model would provide an estimate of the child’s language ability. 

This model outlines an approach similar to Item-Response Theory [IRT; @embretson2013item], an influential and popular psychometric modeling framework for understanding the performance of test takers (in our case language learners) as they are assessed with a particular set of test items (particular words). 
In particular, IRT models jointly infer both the difficulty of specific test items and the accuracy of specific test takers, recovering these latent parameters from the observed data. 
In the basic Rasch (or 1-parameter logistic) IRT model, a person i responds correctly to item j with probability determined by their ability ($\theta_i$) and the difficulty of item j ($d_j$):

$$ P(y_{i,j} = 1 | \theta_i, d_j) = \frac{1}{1+e^{\theta_i + d_j}} $$

These parameters can easily be mapped onto the accumulator model we have been describing: items are words (e.g. $d_j$ is the difficulty of word j), and $\theta_i$ is child $i$’s estimated latent language ability. 
In typical IRT models, both item difficulties and person abilities are standardized (assumed to be normally-distributed and centered on 0) and unit-free. 
However, in principle, it is possible to map these scores to real-world distributions incorporating measured word frequencies and rates of children’s experienced input. 
With this mapping into absolute units, this kind of model can provide a quantitative linking hypothesis between measurements of input and learning. 
Recognizing the parallels between the standard model desiderata and IRT theory, we can use standard extensions of the 1PL (Rasch) model to include both item-level and person-level covariates. 
Item-level (word-level) covariates of central interest are estimates of word frequency in child-directed speech, as well as lexical class [e.g., noun, predicate, or function word; @goodman2008does; @braginsky2019]. 
Person-level covariates of interest might include sex, socioeconomic status variables, or other demographic information. 

This model as described above formalizes an important and testable claim: is the amount of language experience the important predictor of learning for a child, or are there other age-related factors beyond experience? 
Put simply, is a 2-year-old different than a 1-year-old, aside from having twice as much experience with each word? 
This theoretical question can be answered by simple model comparison between two versions of the standard model, one in which age is a person-level covariate, and one in which age is a scalar on the prevalence of each item (i.e., the frequency of "dog" for a 2-year-old is twice that of a 1-year-old). 
Using the IRT framework to formalize theoretical questions and assess them via model comparison is a strength of this approach. 

We report the results of this model comparison, fit to parent-reported vocabulary data from 5,492 English-speaking children in Wordbank. 
Each model estimated parameters for each child’s ability, and for the 680 words on the CDI Words and Sentences form [@fenson2007]. 
Covariates were each word's lexical class (function word, adjective, noun, verb, or other) and the estimated number of monthly tokens a child hears (range: 0.2 - 19,286 tokens), based on child-directed speech from CHILDES [@macwhinney2000childes]. 
This model expects an average child to receive 1,200 words/hour, 12 hours/day, for a total of 438,300 tokens/month, of which 285,200 tokens (65.1%) are  tokens of CDI words. 

In Model 1, we included age as a person-level covariate, allowing for interactions of age (in months), lexical class, and monthly tokens per word. 
Model 2 dropped the age covariate and instead scaled the expected tokens/month for each word by child age, yielding an estimate of lifetime tokens per word and also allowed for interactions with lexical class. 
Model selection metrics (AIC and BIC) preferred the more complex Model 1. 
Predicted acquisition curves from Model 1 are shown in Figure 3 by age, lexical class, and prevalence (left), revealing that nouns are learned more rapidly than verbs or function words, and that there are interactions of prevalence and word type (e.g., more frequent nouns are learned earlier, but there is little effect of prevalence for verbs and function words). 
Moreover, the model predicts item-level acquisition curves (Figure 3, right): e.g., "ball" is learned earlier than "dog" and "go" is easier than "have." 
Model 1 represents a new baseline standard model, which might be extended to include person-level groups such as SES and sex, as well as item-level covariates such as word length. 

These models also estimate a latent language ability for each child, but currently do not specify whether/how this value changes over time. 
However, this ability is no doubt correlated with age, as well as with features related to input quality. 
Estimating the contributions of these factors and determining whether/how language ability changes over developmental time is not possible with current datasets.
Thus, we conclude by discussing the next steps needed to test and build upon the standard model.


```{r, out.width="1.0\\linewidth", include=TRUE, fig.align="center", fig.cap=c("Predicted acquisition curves from a fitted English IRT model as a function of lexical class and the number of expected tokens per month (left), and for a sample of the 680 words on the CDI (right)."), echo=FALSE}
knitr::include_graphics("./figs/fig3_predicted_age_LC_and_items.pdf")
```

# Onward from the Standard Model

The goal of a computational theory like the "standard model" is to describe the quantitative predictions that arise from a set of assumptions. 
Often, however, it is the *failure* of such a model to predict observed patterns of data that is most useful, as these failures point the way forward towards future refinements [@vanrooij2020theory]. 
We discuss three potential failures here. 

**Leveraged learning and the role of processing**. As the model results show, older children accumulate language from their input faster than younger children. 
There are at least three non-mutually exclusive potential reasons for this.
First, older children may be better at remembering their experiences due to independent developmental/maturational factors. 
Another possibility is that children *leverage* their knowledge of language to learn faster through any of several proposed mechanisms [@mitchell2009]. 
For example, if children reason about new words by exclusion [@markman1988children], they get better at learning new words just by having more potential items to exclude from consideration. 
A third possibility is that children are getting better at using the words they know. 
Several recent studies found that a surprising proportion of variance in the rate of young children’s vocabulary growth is accounted for by the speed with which individual children are able to process familiar words [e.g., @fernald2006picking; @marchman2016early].
Disentangling these distinct explanations will require careful measurement of both vocabulary and the potential mechanisms of leverage [cf. @lewis2020role]. 

**Beyond vocabulary**. The "standard model" proposed here models the accumulation of words.
Yet, of course, language is a rich, complex system in which words are inflected morphologically and composed syntactically to express compositional meanings. 
In early views, syntax and morphology were conceptualized as distinct and unconnected, but this conception has not been borne out empirically. 
Instead, evidence shows again and again that the language system is "tightly woven," with extremely tight correlations between the acquisition of words, morphology, and syntax [@bornstein2013language,@wordbankbook]. 
Theoretically, accumulator models like the standard model are generic models of skill acquisition. 
If language learning is a form of skill acquisition [@chater2018language], such connections could lead the way towards extensions of the standard model to the accumulation of broader units of language-like constructions. 

**A theory for understanding acquisition in diverse contexts**. The "standard model" formalizes an implict assumption: namely, that early language learning follows the same general model for all children, even those in radically different circumstances. 
Yet this assumption could very well be false. 
Some children might learn more from overheard speech and others might learn more from child-directed speech [@sperry2019]. 
The kind of data necessary to test this assumption directly are only now being collected, for example, in studies that rigorously track learning outcomes and amount of language input in diverse populations [e.g., comparisons between children in low-income, rural, indigenous communities and those in higher-income Western contexts; @casillas2020].

# Conclusions

An implicit theory drives much research and policy-making on early language acquisition: early language accumulates through discrete experiences with individual words. 
The more experiences, the faster the words are learned. 
This implicit theory can be expressed as a simple computational model that makes quantitative predictions. 
By situating this model in a common psychometric framework, we show how it can be used to connect to large-scale, cross-linguistic datasets. 
This "standard model" synthesizes measures of language input and vocabulary growth, allowing us to formalize, test, and iteratively improve our theoretical understanding of early language acquisition. 
Moreover, this formalization allows us to identify specific gaps in current empirical approaches that must be closed to inform future theory development.

\newpage

# References
```{r create_r-references}
#r_refs(file = "references.bib") # 31 refs right now
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
